{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dara\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\albumentations\\__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.22). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import jaccard_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logger = logging.getLogger(\"test_logger\")\n",
    "test_logger.setLevel(logging.INFO)\n",
    "file_handler = logging.FileHandler(\"test_results.log\", mode=\"w\")\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "file_handler.setFormatter(formatter)\n",
    "test_logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 20\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_augmentations():\n",
    "    return A.Compose([\n",
    "        A.Resize(256, 256),\n",
    "\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=180, border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.6),\n",
    "        A.GaussNoise(var_limit=(1.0, 3.0), mean=0.0, p=0.1),\n",
    "        A.MultiplicativeNoise(multiplier=(0.9, 1.1), per_channel=True, p=0.2),\n",
    "        A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
    "        A.CoarseDropout(\n",
    "            max_holes=2,\n",
    "            max_height=16,\n",
    "            max_width=16,\n",
    "            min_holes=1,\n",
    "            min_height=8,\n",
    "            min_width=8,\n",
    "            fill_value=0,\n",
    "            p=0.1\n",
    "        ),\n",
    "\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ], additional_targets={'mask': 'mask'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolypDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.*\")))\n",
    "        self.mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*.*\")))\n",
    "        assert len(self.image_paths) == len(self.mask_paths), \\\n",
    "            f\"Number of images ({len(self.image_paths)}) and masks ({len(self.mask_paths)}) don't match!\"\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.cvtColor(cv2.imread(self.image_paths[idx]), cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "            # Ensure mask is float32 and in [0,1] range\n",
    "            mask = mask.float() / 256.0\n",
    "        else:\n",
    "            image = cv2.resize(image, (256, 256)) / 256.0  \n",
    "            mask = (cv2.resize(mask, (256, 256)) > 127).astype(np.float32)  \n",
    "            image = (image - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
    "            image = torch.from_numpy(image.transpose(2, 0, 1)).float()\n",
    "            mask = torch.from_numpy(mask).unsqueeze(0).float()  \n",
    "            \n",
    "        filename = os.path.basename(self.image_paths[idx])\n",
    "        return image, mask, filename\n",
    "\n",
    "def metrics(y_true, y_pred, y_prob):\n",
    "    # Convert tensors to numpy arrays if needed\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "    if isinstance(y_prob, torch.Tensor): \n",
    "        y_prob = y_prob.cpu().numpy()\n",
    "\n",
    "    # Prepare binary labels (image-level)\n",
    "    y_true_binar = []\n",
    "    y_pred_binar = []\n",
    "    y_prob_binar = []\n",
    "    \n",
    "    for i in range(len(y_true)):\n",
    "        y_true_binar.append(int(y_true[i].any()))\n",
    "        y_pred_binar.append(int(y_pred[i].any()))\n",
    "        y_prob_binar.append(float(y_prob[i].mean()))  \n",
    "\n",
    "    y_true_flat = y_true.flatten().astype(int)\n",
    "    y_pred_flat = (y_pred.flatten() > treshold).astype(int)\n",
    "    \n",
    "    # Calculate pixel-level metrics\n",
    "    iou = jaccard_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "\n",
    "        \n",
    "    dice = (2. * np.sum(y_true_flat * y_pred_flat)) / (np.sum(y_true_flat) + np.sum(y_pred_flat) + 1e-8)\n",
    "    \n",
    "    # Calculate image-level metrics\n",
    "\n",
    "    rec = recall_score(y_true_binar, y_pred_binar, zero_division=0)\n",
    "    prec = precision_score(y_true_binar, y_pred_binar, zero_division=0)\n",
    "    f1 = f1_score(y_true_binar, y_pred_binar, zero_division=0)\n",
    "    auc = roc_auc_score(y_true_binar, y_prob_binar)  \n",
    "\n",
    "\n",
    "    return iou, rec, prec, f1, auc, dice\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # Ensure target is float (in case it's not)\n",
    "        target = target.float()\n",
    "        \n",
    "        smooth = 1.0\n",
    "        pred = pred.contiguous().view(-1)\n",
    "        target = target.contiguous().view(-1)\n",
    "        \n",
    "        # BCE Loss\n",
    "        bce_loss = self.bce(pred, target)\n",
    "        \n",
    "        # Dice Loss\n",
    "        intersection = (pred * target).sum()\n",
    "        dice_coeff = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "        dice_loss = 1 - dice_coeff\n",
    "        \n",
    "        return dice_loss + bce_loss\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, writer, epoch, dataset_name, treshold):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_y_prob = []\n",
    "    for images, masks, _ in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        probs = torch.sigmoid(outputs).detach()\n",
    "        preds = (torch.sigmoid(outputs > treshold).float().detach())\n",
    "        \n",
    "        all_y_true.append(masks.cpu().numpy())\n",
    "        all_y_pred.append(preds.cpu().numpy())\n",
    "        all_y_prob.append(probs.cpu().numpy()) \n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    all_y_true = np.concatenate(all_y_true, axis=0)\n",
    "    all_y_pred = np.concatenate(all_y_pred, axis=0)\n",
    "    all_y_prob = np.concatenate(all_y_prob, axis=0)\n",
    "\n",
    "    iou, recall, precision, f1, auc, dice = metrics(all_y_true, all_y_pred, all_y_prob)\n",
    "\n",
    "    writer.add_scalar(f\"Loss/Train/{dataset_name}\", epoch_loss, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Train_IoU/{dataset_name}\", iou, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Train_Recall/{dataset_name}\", recall, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Train_Precision/{dataset_name}\", precision, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Train_F1/{dataset_name}\", f1, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Train_AUC/{dataset_name}\", auc, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Train_DICE/{dataset_name}\", dice, epoch)\n",
    "    torch.cuda.empty_cache()\n",
    "    return epoch_loss, iou, recall, precision, f1, auc, dice\n",
    "\n",
    "def validate(model, dataloader, criterion, device, writer, epoch, dataset_name, treshold):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_y_prob = []\n",
    "\n",
    "    for images, masks, _ in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "        probs = torch.sigmoid(outputs).detach()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = (torch.sigmoid(outputs) > treshold).float()\n",
    "        all_y_true.append(masks.cpu().numpy())\n",
    "        all_y_pred.append(preds.cpu().numpy())\n",
    "        all_y_prob.append(probs.cpu().numpy()) \n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    all_y_true = np.concatenate(all_y_true, axis=0)\n",
    "    all_y_pred = np.concatenate(all_y_pred, axis=0)\n",
    "    all_y_prob = np.concatenate(all_y_prob, axis=0)\n",
    "\n",
    "\n",
    "    iou, recall, precision, f1, auc, dice = metrics(all_y_true, all_y_pred, all_y_prob)\n",
    "\n",
    "    writer.add_scalar(f\"Loss/Val/{dataset_name}\", epoch_loss, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Val_IoU/{dataset_name}\", iou, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Val_Recall/{dataset_name}\", recall, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Val_Precision/{dataset_name}\", precision, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Val_F1/{dataset_name}\", f1, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Val_AUC/{dataset_name}\", auc, epoch)\n",
    "    writer.add_scalar(f\"Metrics/Val_Train_DICE/{dataset_name}\", dice, epoch)\n",
    "\n",
    "    return epoch_loss, iou, recall, precision, f1, auc, dice\n",
    "\n",
    "def test_model(model, dataloader, criterion, device, save_folder=\".\", treshold = 0.502):\n",
    "    test_logger.info(\"Начало тестирования...\")\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_y_prob = []\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks, filenames in tqdm(dataloader, desc=\"Testing\"):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > treshold).float()\n",
    "            probs = torch.sigmoid(outputs).detach()\n",
    "\n",
    "            all_y_true.append(masks.cpu().numpy())\n",
    "            all_y_pred.append(preds.cpu().numpy())\n",
    "            all_y_prob.append(probs.cpu().numpy())\n",
    "\n",
    "            preds_np = preds.cpu().numpy()  \n",
    "            for i in range(preds_np.shape[0]):\n",
    "                mask_pred = preds_np[i, 0]\n",
    "                mask_img = (mask_pred * 255).astype(np.uint8)\n",
    "                save_path = os.path.join(save_folder, filenames[i])\n",
    "                cv2.imwrite(save_path, mask_img)\n",
    "\n",
    "    test_loss = running_loss / len(dataloader.dataset)\n",
    "    all_y_true = np.concatenate(all_y_true, axis=0)\n",
    "    all_y_pred = np.concatenate(all_y_pred, axis=0)\n",
    "    all_y_prob = np.concatenate(all_y_prob, axis=0)\n",
    "                                 \n",
    "    iou, recall, precision, f1, auc, dice = metrics(all_y_true, all_y_pred, all_y_prob)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"IoU: {iou:.4f} | Recall: {recall:.4f} | Precision: {precision:.4f} | F1 Score: {f1:.4f} | AUC Score: {auc:.4f} | DICE: {dice:.4f}\")\n",
    "    \n",
    "    test_logger.info(f\"Test Loss: {test_loss:.4f}\")\n",
    "    test_logger.info(f\"IoU: {iou:.4f} | Recall: {recall:.4f} | Precision: {precision:.4f} | F1 Score: {f1:.4f} | AUC Score: {auc:.4f} | DICE: {dice:.4f}\")\n",
    "\n",
    "    return test_loss, iou, recall, precision, f1, auc, dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\"name\": \"40_60\", \n",
    "     \"train_image_dir\": 'C:/Users/Dara/Desktop/Final_thesis/data_choosing/Images/train/40_60',\n",
    "     \"train_mask_dir\": \"C:/Users/Dara/Desktop/Final_thesis/data_choosing/Masks/train/40_60\",\n",
    "     \"val_image_dir\": \"C:/Users/Dara/Desktop/Final_thesis/data_choosing/Images/val\",\n",
    "     \"val_mask_dir\": \"C:/Users/Dara/Desktop/Final_thesis/data_choosing/Masks/val\",\n",
    "     \"test_image_dir\": \"C:/Users/Dara/Desktop/Final_thesis/data_choosing/Images/test\",\n",
    "     \"test_mask_dir\": \"C:/Users/Dara/Desktop/Final_thesis//data_choosing/Masks/test\"}\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on dataset: 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_556\\1662773873.py:11: UserWarning: Argument 'fill_value' is not valid and will be ignored.\n",
      "  A.CoarseDropout(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8011 | IoU: 0.4294 | Recall: 0.9239 | Precision: 0.7608 | F1: 0.8345| AUC Score: 0.6850 | DICE: 0.6008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6187 | IoU: 0.7339 | Recall: 1.0000 | Precision: 0.8571 | F1: 0.9231 | AUC Score: 0.9375 | DICE: 0.8466\n",
      "Новая лучшая модель сохранена.\n",
      "Эпоха 2/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4367 | IoU: 0.5960 | Recall: 0.8812 | Precision: 0.8815 | F1: 0.8814| AUC Score: 0.8932 | DICE: 0.7469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4936 | IoU: 0.7765 | Recall: 0.9167 | Precision: 1.0000 | F1: 0.9565 | AUC Score: 1.0000 | DICE: 0.8742\n",
      "Новая лучшая модель сохранена.\n",
      "Эпоха 3/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3691 | IoU: 0.6379 | Recall: 0.8824 | Precision: 0.9078 | F1: 0.8949| AUC Score: 0.9242 | DICE: 0.7789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4460 | IoU: 0.8073 | Recall: 1.0000 | Precision: 1.0000 | F1: 1.0000 | AUC Score: 1.0000 | DICE: 0.8934\n",
      "Новая лучшая модель сохранена.\n",
      "Эпоха 4/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3452 | IoU: 0.6523 | Recall: 0.8910 | Precision: 0.9168 | F1: 0.9037| AUC Score: 0.9320 | DICE: 0.7896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4576 | IoU: 0.7687 | Recall: 1.0000 | Precision: 1.0000 | F1: 1.0000 | AUC Score: 1.0000 | DICE: 0.8692\n",
      "Эпоха 5/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3258 | IoU: 0.6670 | Recall: 0.8911 | Precision: 0.9284 | F1: 0.9093| AUC Score: 0.9373 | DICE: 0.8002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4268 | IoU: 0.8370 | Recall: 1.0000 | Precision: 1.0000 | F1: 1.0000 | AUC Score: 1.0000 | DICE: 0.9113\n",
      "Новая лучшая модель сохранена.\n",
      "Эпоха 6/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3246 | IoU: 0.6718 | Recall: 0.9028 | Precision: 0.9270 | F1: 0.9148| AUC Score: 0.9398 | DICE: 0.8037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4940 | IoU: 0.7560 | Recall: 1.0000 | Precision: 1.0000 | F1: 1.0000 | AUC Score: 1.0000 | DICE: 0.8611\n",
      "Эпоха 7/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3228 | IoU: 0.6731 | Recall: 0.9008 | Precision: 0.9233 | F1: 0.9119| AUC Score: 0.9410 | DICE: 0.8046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4018 | IoU: 0.8784 | Recall: 1.0000 | Precision: 0.9231 | F1: 0.9600 | AUC Score: 1.0000 | DICE: 0.9353\n",
      "Новая лучшая модель сохранена.\n",
      "Эпоха 8/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2835 | IoU: 0.7017 | Recall: 0.8950 | Precision: 0.9473 | F1: 0.9204| AUC Score: 0.9502 | DICE: 0.8247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4623 | IoU: 0.7695 | Recall: 1.0000 | Precision: 0.9231 | F1: 0.9600 | AUC Score: 0.9792 | DICE: 0.8697\n",
      "Эпоха 9/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2831 | IoU: 0.7022 | Recall: 0.9044 | Precision: 0.9437 | F1: 0.9236| AUC Score: 0.9504 | DICE: 0.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4716 | IoU: 0.7193 | Recall: 1.0000 | Precision: 0.9231 | F1: 0.9600 | AUC Score: 0.9444 | DICE: 0.8367\n",
      "Эпоха 10/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2885 | IoU: 0.6990 | Recall: 0.9036 | Precision: 0.9375 | F1: 0.9202| AUC Score: 0.9447 | DICE: 0.8229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4494 | IoU: 0.8027 | Recall: 1.0000 | Precision: 1.0000 | F1: 1.0000 | AUC Score: 1.0000 | DICE: 0.8906\n",
      "Эпоха 11/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2794 | IoU: 0.7017 | Recall: 0.9045 | Precision: 0.9439 | F1: 0.9238| AUC Score: 0.9534 | DICE: 0.8247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4856 | IoU: 0.7521 | Recall: 0.9167 | Precision: 0.9167 | F1: 0.9167 | AUC Score: 0.9444 | DICE: 0.8585\n",
      "Эпоха 12/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2842 | IoU: 0.7029 | Recall: 0.9014 | Precision: 0.9483 | F1: 0.9242| AUC Score: 0.9558 | DICE: 0.8255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4050 | IoU: 0.8651 | Recall: 1.0000 | Precision: 0.9231 | F1: 0.9600 | AUC Score: 1.0000 | DICE: 0.9277\n",
      "Эпоха 13/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2654 | IoU: 0.7137 | Recall: 0.9111 | Precision: 0.9498 | F1: 0.9301| AUC Score: 0.9586 | DICE: 0.8329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3998 | IoU: 0.8802 | Recall: 1.0000 | Precision: 1.0000 | F1: 1.0000 | AUC Score: 1.0000 | DICE: 0.9363\n",
      "Новая лучшая модель сохранена.\n",
      "Эпоха 14/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2714 | IoU: 0.7132 | Recall: 0.9089 | Precision: 0.9494 | F1: 0.9287| AUC Score: 0.9557 | DICE: 0.8326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4065 | IoU: 0.8739 | Recall: 1.0000 | Precision: 1.0000 | F1: 1.0000 | AUC Score: 1.0000 | DICE: 0.9327\n",
      "Эпоха 15/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2592 | IoU: 0.7245 | Recall: 0.9063 | Precision: 0.9545 | F1: 0.9298| AUC Score: 0.9617 | DICE: 0.8402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4510 | IoU: 0.7792 | Recall: 1.0000 | Precision: 0.9231 | F1: 0.9600 | AUC Score: 0.9236 | DICE: 0.8759\n",
      "Эпоха 16/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2684 | IoU: 0.7152 | Recall: 0.9092 | Precision: 0.9479 | F1: 0.9282| AUC Score: 0.9598 | DICE: 0.8339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4110 | IoU: 0.8440 | Recall: 1.0000 | Precision: 1.0000 | F1: 1.0000 | AUC Score: 1.0000 | DICE: 0.9154\n",
      "Эпоха 17/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2674 | IoU: 0.7188 | Recall: 0.9049 | Precision: 0.9492 | F1: 0.9265| AUC Score: 0.9599 | DICE: 0.8364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4284 | IoU: 0.8290 | Recall: 1.0000 | Precision: 1.0000 | F1: 1.0000 | AUC Score: 1.0000 | DICE: 0.9065\n",
      "Эпоха 18/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2491 | IoU: 0.7331 | Recall: 0.9088 | Precision: 0.9582 | F1: 0.9328| AUC Score: 0.9647 | DICE: 0.8460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4257 | IoU: 0.8230 | Recall: 1.0000 | Precision: 1.0000 | F1: 1.0000 | AUC Score: 1.0000 | DICE: 0.9029\n",
      "Эпоха 19/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2408 | IoU: 0.7415 | Recall: 0.9136 | Precision: 0.9569 | F1: 0.9347| AUC Score: 0.9639 | DICE: 0.8516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3996 | IoU: 0.8902 | Recall: 1.0000 | Precision: 1.0000 | F1: 1.0000 | AUC Score: 1.0000 | DICE: 0.9419\n",
      "Новая лучшая модель сохранена.\n",
      "Эпоха 20/20 для датасета 40_60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2593 | IoU: 0.7258 | Recall: 0.9066 | Precision: 0.9515 | F1: 0.9285| AUC Score: 0.9580 | DICE: 0.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3894 | IoU: 0.8912 | Recall: 1.0000 | Precision: 0.9231 | F1: 0.9600 | AUC Score: 1.0000 | DICE: 0.9425\n",
      "Новая лучшая модель сохранена.\n",
      "Обучение завершено для датасета 40_60. Лучшая модель на эпохе 20 с  DICE: 0.9425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 193/193 [00:28<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5082\n",
      "IoU: 0.7995 | Recall: 0.9647 | Precision: 0.9810 | F1 Score: 0.9727 | AUC Score: 0.9939 | DICE: 0.8886\n",
      "  Dataset  Best Epoch  Test IoU  Test Recall  Test Precision   Test F1  \\\n",
      "0   40_60          20  0.799537     0.964657        0.980973  0.972746   \n",
      "\n",
      "   Test Loss  Test AUC  Test DICE  \n",
      "0   0.508215  0.993936   0.888603  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "treshold = 0.502\n",
    "results = []\n",
    "encoder_name = \"resnet34\"  \n",
    "\n",
    "\n",
    "dataset_name = dataset[\"name\"]\n",
    "print(f\"Training on dataset: {dataset_name}\")\n",
    "\n",
    "train_dataset = PolypDataset(dataset[\"train_image_dir\"], dataset[\"train_mask_dir\"], transform=get_train_augmentations())\n",
    "val_dataset = PolypDataset(dataset[\"val_image_dir\"], dataset[\"val_mask_dir\"])\n",
    "test_dataset = PolypDataset(dataset[\"test_image_dir\"], dataset[\"test_mask_dir\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=encoder_name,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    activation=\"sigmoid\"\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = DiceBCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "log_dir = f\"logs/{dataset_name}_{encoder_name}\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "patience = 10\n",
    "best_val_dice = 0.0  \n",
    "best_epoch = -1\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Эпоха {epoch+1}/{num_epochs} для датасета {dataset_name}\")\n",
    "    \n",
    "    train_loss, train_iou, train_recall, train_precision, train_f1,train_auc, train_dice = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, writer, epoch, dataset_name,treshold = 0.502)\n",
    "    print(f\"Train Loss: {train_loss:.4f} | IoU: {train_iou:.4f} | Recall: {train_recall:.4f} | Precision: {train_precision:.4f} | F1: {train_f1:.4f}| AUC Score: {train_auc:.4f} | DICE: {train_dice:.4f}\")\n",
    "    \n",
    "    val_loss, val_iou, val_recall, val_precision, val_f1, val_auc, val_dice= validate(\n",
    "        model, val_loader, criterion, device, writer, epoch, dataset_name,treshold = 0.502)\n",
    "    print(f\"Val Loss: {val_loss:.4f} | IoU: {val_iou:.4f} | Recall: {val_recall:.4f} | Precision: {val_precision:.4f} | F1: {val_f1:.4f} | AUC Score: {val_auc:.4f} | DICE: {val_dice:.4f}\")\n",
    "\n",
    "    if val_dice > best_val_dice:\n",
    "        best_val_dice = val_dice\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), f\"unetplusplus_{dataset_name}_best_model.pth\")\n",
    "        print(\"Новая лучшая модель сохранена.\")\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Ранняя остановка на эпохе {epoch+1}\")\n",
    "            break\n",
    "\n",
    "print(f\"Обучение завершено для датасета {dataset_name}. Лучшая модель на эпохе {best_epoch+1} с  DICE: {best_val_dice:.4f}\")\n",
    "\n",
    "model.load_state_dict(torch.load(f\"unetplusplus_{dataset_name}_best_model.pth\"))\n",
    "test_loss, test_iou, test_recall, test_precision, test_f1, test_auc, test_dice = test_model(\n",
    "    model, test_loader, criterion, device, save_folder=f\"predicted_maskss_{dataset_name}\", treshold = 0.502)\n",
    "\n",
    "results.append({\n",
    "    \"Dataset\": dataset_name,\n",
    "    \"Best Epoch\": best_epoch + 1,\n",
    "    \"Test IoU\": test_iou,\n",
    "    \"Test Recall\": test_recall,\n",
    "    \"Test Precision\": test_precision,\n",
    "    \"Test F1\": test_f1,\n",
    "    \"Test Loss\": test_loss,\n",
    "    \"Test AUC\": test_auc,\n",
    "    \"Test DICE\": test_dice\n",
    "\n",
    "})\n",
    "\n",
    "writer.close()\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on dataset: EITS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_556\\1662773873.py:11: UserWarning: Argument 'fill_value' is not valid and will be ignored.\n",
      "  A.CoarseDropout(\n",
      "Testing: 100%|██████████| 25/25 [00:07<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4925\n",
      "IoU: 0.3151 | Recall: 1.0000 | Precision: 1.0000 | F1 Score: 1.0000 | AUC Score: nan | DICE: 0.4791\n",
      "  Dataset  Best Epoch  Test IoU  Test Recall  Test Precision  Test F1  \\\n",
      "0    EITS           0  0.315053          1.0             1.0      1.0   \n",
      "\n",
      "   Test Loss  Test AUC  Test DICE  \n",
      "0   0.492481       NaN   0.479148  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dara\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:375: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "treshold = 0.502\n",
    "results = []\n",
    "encoder_name = \"resnet34\"  \n",
    "\n",
    "dataset = {\"name\": \"40_60\", \n",
    "     \"train_image_dir\": 'C:/Users/Dara/Desktop/Final_thesis/data_choosing/Images/train/40_60',\n",
    "     \"train_mask_dir\": \"C:/Users/Dara/Desktop/Final_thesis/data_choosing/Masks/train/40_60\",\n",
    "     \"val_image_dir\": \"C:/Users/Dara/Desktop/Final_thesis/data_choosing/Images/val\",\n",
    "     \"val_mask_dir\": \"C:/Users/Dara/Desktop/Final_thesis/data_choosing/Masks/val\",\n",
    "     \"test_image_dir\": \"C:/Users/Dara/PraNet/Images\",\n",
    "     \"test_mask_dir\": \"C:/Users/Dara/PraNet/Masks\"}\n",
    "\n",
    "data =  dataset[\"name\"]\n",
    "dataset_name = 'EITS'\n",
    "\n",
    "train_dataset = PolypDataset(dataset[\"train_image_dir\"], dataset[\"train_mask_dir\"], transform=get_train_augmentations())\n",
    "val_dataset = PolypDataset(dataset[\"val_image_dir\"], dataset[\"val_mask_dir\"])\n",
    "test_dataset = PolypDataset(dataset[\"test_image_dir\"], dataset[\"test_mask_dir\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=encoder_name,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    activation=\"sigmoid\"\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = DiceBCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "log_dir = f\"logs/{dataset_name}_{encoder_name}\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "patience = 10\n",
    "best_val_dice = 0.0  \n",
    "best_epoch = -1\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(f\"unetplusplus_{data}_best_model.pth\"))\n",
    "test_loss, test_iou, test_recall, test_precision, test_f1, test_auc, test_dice = test_model(\n",
    "    model, test_loader, criterion, device, save_folder=f\"predicted_maskss_{dataset_name}\", treshold = 0.502)\n",
    "\n",
    "results.append({\n",
    "    \"Dataset\": dataset_name,\n",
    "    \"Best Epoch\": best_epoch + 1,\n",
    "    \"Test IoU\": test_iou,\n",
    "    \"Test Recall\": test_recall,\n",
    "    \"Test Precision\": test_precision,\n",
    "    \"Test F1\": test_f1,\n",
    "    \"Test Loss\": test_loss,\n",
    "    \"Test AUC\": test_auc,\n",
    "    \"Test DICE\": test_dice\n",
    "\n",
    "})\n",
    "\n",
    "writer.close()\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
